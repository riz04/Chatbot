{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# part 1\n",
    "import pickle\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"./004 UPDATED-NLP-COURSE/UPDATED_NLP_COURSE/06-Deep-Learning/train_qa.txt\" , \"rb\") as f:\n",
    "    train_data = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"./004 UPDATED-NLP-COURSE/UPDATED_NLP_COURSE/06-Deep-Learning/test_qa.txt\" , \"rb\") as f:\n",
    "    test_data = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['Mary',\n",
       "  'moved',\n",
       "  'to',\n",
       "  'the',\n",
       "  'bathroom',\n",
       "  '.',\n",
       "  'Sandra',\n",
       "  'journeyed',\n",
       "  'to',\n",
       "  'the',\n",
       "  'bedroom',\n",
       "  '.'],\n",
       " ['Is', 'Sandra', 'in', 'the', 'hallway', '?'],\n",
       " 'no')"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Mary moved to the bathroom . Sandra journeyed to the bedroom .'"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# story\n",
    "\" \".join(train_data[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Is Sandra in the hallway ?'"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# question\n",
    "\" \".join(train_data[0][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'no'"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# answer\n",
    "\"\".join(train_data[0][2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to begin with, we need to set up a vocabulary of all the words we have in our dataset\n",
    "# we need to get in account both train and test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data = train_data + test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11000"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(all_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = set()\n",
    "\n",
    "for story,question,answer in all_data:\n",
    "   \n",
    "    vocab = vocab.union(set(story))\n",
    "    vocab = vocab.union(set(question))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab.add(\"no\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab.add(\"yes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'.',\n",
       " '?',\n",
       " 'Daniel',\n",
       " 'Is',\n",
       " 'John',\n",
       " 'Mary',\n",
       " 'Sandra',\n",
       " 'apple',\n",
       " 'back',\n",
       " 'bathroom',\n",
       " 'bedroom',\n",
       " 'discarded',\n",
       " 'down',\n",
       " 'dropped',\n",
       " 'football',\n",
       " 'garden',\n",
       " 'got',\n",
       " 'grabbed',\n",
       " 'hallway',\n",
       " 'in',\n",
       " 'journeyed',\n",
       " 'kitchen',\n",
       " 'left',\n",
       " 'milk',\n",
       " 'moved',\n",
       " 'no',\n",
       " 'office',\n",
       " 'picked',\n",
       " 'put',\n",
       " 'the',\n",
       " 'there',\n",
       " 'to',\n",
       " 'took',\n",
       " 'travelled',\n",
       " 'up',\n",
       " 'went',\n",
       " 'yes'}"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# adding 1, bcz later on when we perform keras sequences we have little placeholder\n",
    "vocab_len = len(vocab) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "38"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# how long is the longest story"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_story_lens = [len(data[0]) for data in all_data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_story_len = max(all_story_lens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "156"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_story_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# how long is the longest question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_questions_lens = [len(data[1]) for data in all_data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_ques_len = max(all_questions_lens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_ques_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "# review\n",
    "# we explored the data\n",
    "# opened it up using pickle functionality\n",
    "# saw, that data is in the form of list\n",
    "# where every item is in the form of tuple\n",
    "# built out a vocabulary using set\n",
    "# using union we kept adding words, until we got all unique words\n",
    "# and then we calculated max story length and max question length\n",
    "# we are gonna use it in keras pad sequences, once we vectorize the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "# part 2\n",
    "# how to vectorize the data\n",
    "# create a function that can vectorize data for us"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.preprocessing.text import Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create an integer encoding for the sequences of words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(filters = [])\n",
    "tokenizer.fit_on_texts(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'took': 1,\n",
       " 'mary': 2,\n",
       " 'apple': 3,\n",
       " 'the': 4,\n",
       " 'bedroom': 5,\n",
       " 'moved': 6,\n",
       " 'travelled': 7,\n",
       " 'left': 8,\n",
       " 'no': 9,\n",
       " 'up': 10,\n",
       " 'garden': 11,\n",
       " 'daniel': 12,\n",
       " 'back': 13,\n",
       " 'kitchen': 14,\n",
       " 'dropped': 15,\n",
       " 'office': 16,\n",
       " '.': 17,\n",
       " 'hallway': 18,\n",
       " 'down': 19,\n",
       " 'football': 20,\n",
       " 'journeyed': 21,\n",
       " 'is': 22,\n",
       " '?': 23,\n",
       " 'put': 24,\n",
       " 'in': 25,\n",
       " 'milk': 26,\n",
       " 'yes': 27,\n",
       " 'sandra': 28,\n",
       " 'john': 29,\n",
       " 'went': 30,\n",
       " 'got': 31,\n",
       " 'bathroom': 32,\n",
       " 'picked': 33,\n",
       " 'discarded': 34,\n",
       " 'grabbed': 35,\n",
       " 'there': 36,\n",
       " 'to': 37}"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.word_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "# how we can vectorize story, question, answer in manual fashion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_story_text = []\n",
    "train_question_text = []\n",
    "train_answers = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "for story,question,answer in train_data:\n",
    "    train_story_text.append(story)\n",
    "    train_question_text.append(question)\n",
    "    train_answers.append(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_story_seq = tokenizer.texts_to_sequences(train_story_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_story_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_story_seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's create a function which can help us vectorize the text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we need to pass max_story_len and max_question_len\n",
    "# bcz, we are going to use padding sequences\n",
    "# not every story and not every question is the same length\n",
    "# but, the actual RNN we are training on, it needs  things to be in same length\n",
    "# so, we will pad it up wit zeros, in case some story is too short\n",
    "# or we want to cut down a story, if its too long\n",
    "\n",
    "def vectorize_stories(data,word_index=tokenizer.word_index,max_story_len = max_story_len,max_ques_len = max_ques_len):\n",
    "    \n",
    "    # stories\n",
    "    X = []\n",
    "    # questions\n",
    "    Xq = []\n",
    "    # correct answer(yes/no)\n",
    "    Y = []\n",
    "    \n",
    "    for story,question,answer in data:\n",
    "        \n",
    "        # for each story in dataset\n",
    "        x = [word_index[word.lower()] for word in story]\n",
    "    \n",
    "        xq = [word_index[word.lower()] for word in question]\n",
    "        \n",
    "        # plus 1, bcz index 0 is reserved when we use pad sequences\n",
    "        y = np.zeros(len(word_index) + 1)\n",
    "        y[word_index[answer]] = 1\n",
    "        \n",
    "        \n",
    "        X.append(x)\n",
    "        Xq.append(xq)\n",
    "        Y.append(y)\n",
    "        \n",
    "    return (pad_sequences(X,maxlen= max_story_len), pad_sequences(Xq,maxlen = max_ques_len), np.array(Y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs_train, questions_train, answers_train = vectorize_stories(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs_test, questions_test, answers_test = vectorize_stories(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0,  0,  0, ...,  4,  5, 17],\n",
       "       [ 0,  0,  0, ...,  4, 11, 17],\n",
       "       [ 0,  0,  0, ...,  4, 11, 17],\n",
       "       ...,\n",
       "       [ 0,  0,  0, ...,  4,  3, 17],\n",
       "       [ 0,  0,  0, ...,  4, 11, 17],\n",
       "       [ 0,  0,  0, ...,  3, 36, 17]], dtype=int32)"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answers_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.word_index[\"no\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "27"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.word_index[\"yes\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0., 503.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0., 497.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.])"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# there are 503 1's at index location 9, or 503 no's\n",
    "# there are 497 1's at index location 27, or 497 yes's\n",
    "sum(answers_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we have successfully vectorized our stories, questions and answers\n",
    "# now we have data in the correct format for creating the model with keras layers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "# part 3\n",
    "# building neural network\n",
    "# - input encoder M\n",
    "# - input encoder C\n",
    "# - Question Encoder\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential,Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers.embeddings import Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Input,Activation,Dense,Permute,Dropout,add,dot,concatenate,LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we have story that encoder needs to understand\n",
    "# we need to map and story and question to achive the results\n",
    "# we will create placeholders using input functions of keras\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we are creating placeholders to recive input\n",
    "# placeholder shape = (max_story_len , batch_size)\n",
    "input_sequence = Input((max_story_len,))\n",
    "question1 = Input((max_ques_len,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = len(vocab) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "# INPUT ENCODER M\n",
    "# this input gets embedded, to a sequence of vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_encoder_m = Sequential()\n",
    "input_encoder_m.add(Embedding(input_dim = vocab_size , output_dim = 64))\n",
    "input_encoder_m.add(Dropout(0.3))\n",
    "\n",
    "# dropout = o.5 means that 50% of the neurons will be dropped out randomly during training\n",
    "# and that helps with overfitting\n",
    "\n",
    "# this encoder is going to output in the form of \n",
    "# (samples, story_maxlen, embedding_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "# INPUT ENCODER C\n",
    "input_encoder_c = Sequential()\n",
    "input_encoder_c.add(Embedding(input_dim = vocab_size , output_dim = max_ques_len))\n",
    "input_encoder_c.add(Dropout(0.3))\n",
    "\n",
    "# this encoder is going to output in the form of \n",
    "# (samples, story_maxlen, max_question_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "question_encoder= Sequential()\n",
    "question_encoder.add(Embedding(input_dim = vocab_size , output_dim = 64, input_length = max_ques_len))\n",
    "question_encoder.add(Dropout(0.3))\n",
    "\n",
    "# (samples,question_maxlen,embedding_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "# encoded <-- encoder(input)\n",
    "input_encoded_m = input_encoder_m(input_sequence)\n",
    "input_encoded_c = input_encoder_c(input_sequence)\n",
    "question_encoded = question_encoder(question1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "match = dot([input_encoded_m,question_encoded],axes = (2,2))\n",
    "match = Activation(\"softmax\")(match)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = add([match , input_encoded_c])\n",
    "response = Permute((2,1))(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "answer = concatenate([response,question_encoded])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'concatenate_2/concat:0' shape=(?, 6, 220) dtype=float32>"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "answer = LSTM(32)(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "answer = Dropout(0.5)(answer)\n",
    "answer = Dense(vocab_size)(answer)   #(samples, vocab_size)  Yes/No 0000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "answer = Activation(\"softmax\")(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "# answer links together all the encoders\n",
    "model = Model([input_sequence,question1],answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=\"rmsprop\" , loss = \"categorical_crossentropy\" ,metrics = [\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_2 (InputLayer)            (None, 156)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_3 (InputLayer)            (None, 6)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "sequential_6 (Sequential)       multiple             2432        input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "sequential_8 (Sequential)       (None, 6, 64)        2432        input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dot_1 (Dot)                     (None, 156, 6)       0           sequential_6[2][0]               \n",
      "                                                                 sequential_8[2][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 156, 6)       0           dot_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "sequential_7 (Sequential)       multiple             228         input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "add_1 (Add)                     (None, 156, 6)       0           activation_1[0][0]               \n",
      "                                                                 sequential_7[2][0]               \n",
      "__________________________________________________________________________________________________\n",
      "permute_1 (Permute)             (None, 6, 156)       0           add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 6, 220)       0           permute_1[0][0]                  \n",
      "                                                                 sequential_8[2][0]               \n",
      "__________________________________________________________________________________________________\n",
      "lstm_1 (LSTM)                   (None, 32)           32384       concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_7 (Dropout)             (None, 32)           0           lstm_1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 38)           1254        dropout_7[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, 38)           0           dense_1[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 38,730\n",
      "Trainable params: 38,730\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "# part 4\n",
    "# train and fit our model\n",
    "# evaluate the model on given test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/riz04/anaconda3/envs/nlp_course/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "WARNING:tensorflow:From /home/riz04/anaconda3/envs/nlp_course/lib/python3.6/site-packages/tensorflow/python/ops/math_grad.py:102: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Deprecated in favor of operator or tf.math.divide.\n",
      "Train on 10000 samples, validate on 1000 samples\n",
      "Epoch 1/100\n",
      "10000/10000 [==============================] - 10s 961us/step - loss: 0.9342 - acc: 0.4905 - val_loss: 0.6947 - val_acc: 0.4970\n",
      "Epoch 2/100\n",
      "10000/10000 [==============================] - 6s 561us/step - loss: 0.7050 - acc: 0.5007 - val_loss: 0.6950 - val_acc: 0.5030\n",
      "Epoch 3/100\n",
      "10000/10000 [==============================] - 5s 539us/step - loss: 0.6968 - acc: 0.4939 - val_loss: 0.6948 - val_acc: 0.4970\n",
      "Epoch 4/100\n",
      "10000/10000 [==============================] - 5s 547us/step - loss: 0.6950 - acc: 0.5014 - val_loss: 0.6949 - val_acc: 0.5030\n",
      "Epoch 5/100\n",
      "10000/10000 [==============================] - 5s 541us/step - loss: 0.6952 - acc: 0.4918 - val_loss: 0.6936 - val_acc: 0.5030\n",
      "Epoch 6/100\n",
      "10000/10000 [==============================] - 5s 547us/step - loss: 0.6947 - acc: 0.4955 - val_loss: 0.6937 - val_acc: 0.4970\n",
      "Epoch 7/100\n",
      "10000/10000 [==============================] - 5s 545us/step - loss: 0.6941 - acc: 0.5036 - val_loss: 0.6933 - val_acc: 0.5030\n",
      "Epoch 8/100\n",
      "10000/10000 [==============================] - 6s 583us/step - loss: 0.6948 - acc: 0.5056 - val_loss: 0.6971 - val_acc: 0.5030\n",
      "Epoch 9/100\n",
      "10000/10000 [==============================] - 6s 586us/step - loss: 0.6944 - acc: 0.5049 - val_loss: 0.6951 - val_acc: 0.4910\n",
      "Epoch 10/100\n",
      "10000/10000 [==============================] - 6s 584us/step - loss: 0.6943 - acc: 0.5070 - val_loss: 0.6922 - val_acc: 0.4840\n",
      "Epoch 11/100\n",
      "10000/10000 [==============================] - 6s 566us/step - loss: 0.6875 - acc: 0.5330 - val_loss: 0.6846 - val_acc: 0.5040\n",
      "Epoch 12/100\n",
      "10000/10000 [==============================] - 6s 559us/step - loss: 0.6741 - acc: 0.5781 - val_loss: 0.6596 - val_acc: 0.6390\n",
      "Epoch 13/100\n",
      "10000/10000 [==============================] - 6s 584us/step - loss: 0.6500 - acc: 0.6191 - val_loss: 0.6267 - val_acc: 0.6610\n",
      "Epoch 14/100\n",
      "10000/10000 [==============================] - 5s 543us/step - loss: 0.6278 - acc: 0.6510 - val_loss: 0.5945 - val_acc: 0.6940\n",
      "Epoch 15/100\n",
      "10000/10000 [==============================] - 5s 545us/step - loss: 0.5980 - acc: 0.6823 - val_loss: 0.5675 - val_acc: 0.7120\n",
      "Epoch 16/100\n",
      "10000/10000 [==============================] - 5s 545us/step - loss: 0.5729 - acc: 0.7002 - val_loss: 0.5340 - val_acc: 0.7390\n",
      "Epoch 17/100\n",
      "10000/10000 [==============================] - 5s 546us/step - loss: 0.5501 - acc: 0.7128 - val_loss: 0.5306 - val_acc: 0.7220\n",
      "Epoch 18/100\n",
      "10000/10000 [==============================] - 5s 530us/step - loss: 0.5427 - acc: 0.7259 - val_loss: 0.5167 - val_acc: 0.7410\n",
      "Epoch 19/100\n",
      "10000/10000 [==============================] - 5s 532us/step - loss: 0.5163 - acc: 0.7384 - val_loss: 0.4916 - val_acc: 0.7640\n",
      "Epoch 20/100\n",
      "10000/10000 [==============================] - 5s 532us/step - loss: 0.5087 - acc: 0.7514 - val_loss: 0.4812 - val_acc: 0.7690\n",
      "Epoch 21/100\n",
      "10000/10000 [==============================] - 5s 538us/step - loss: 0.4960 - acc: 0.7679 - val_loss: 0.4630 - val_acc: 0.7990\n",
      "Epoch 22/100\n",
      "10000/10000 [==============================] - 5s 540us/step - loss: 0.4843 - acc: 0.7756 - val_loss: 0.4616 - val_acc: 0.7990\n",
      "Epoch 23/100\n",
      "10000/10000 [==============================] - 5s 541us/step - loss: 0.4683 - acc: 0.7887 - val_loss: 0.4632 - val_acc: 0.8000\n",
      "Epoch 24/100\n",
      "10000/10000 [==============================] - 5s 539us/step - loss: 0.4658 - acc: 0.7904 - val_loss: 0.4587 - val_acc: 0.7950\n",
      "Epoch 25/100\n",
      "10000/10000 [==============================] - 5s 536us/step - loss: 0.4515 - acc: 0.8000 - val_loss: 0.4420 - val_acc: 0.8020\n",
      "Epoch 26/100\n",
      "10000/10000 [==============================] - 5s 532us/step - loss: 0.4446 - acc: 0.8015 - val_loss: 0.4536 - val_acc: 0.8010\n",
      "Epoch 27/100\n",
      "10000/10000 [==============================] - 5s 533us/step - loss: 0.4321 - acc: 0.8045 - val_loss: 0.4329 - val_acc: 0.8040\n",
      "Epoch 28/100\n",
      "10000/10000 [==============================] - 5s 536us/step - loss: 0.4319 - acc: 0.8065 - val_loss: 0.4268 - val_acc: 0.8090\n",
      "Epoch 29/100\n",
      "10000/10000 [==============================] - 5s 538us/step - loss: 0.4226 - acc: 0.8146 - val_loss: 0.4142 - val_acc: 0.8090\n",
      "Epoch 30/100\n",
      "10000/10000 [==============================] - 5s 540us/step - loss: 0.4137 - acc: 0.8119 - val_loss: 0.4390 - val_acc: 0.8070\n",
      "Epoch 31/100\n",
      "10000/10000 [==============================] - 5s 540us/step - loss: 0.4126 - acc: 0.8144 - val_loss: 0.4409 - val_acc: 0.8050\n",
      "Epoch 32/100\n",
      "10000/10000 [==============================] - 6s 551us/step - loss: 0.4053 - acc: 0.8246 - val_loss: 0.4289 - val_acc: 0.8080\n",
      "Epoch 33/100\n",
      "10000/10000 [==============================] - 5s 530us/step - loss: 0.3974 - acc: 0.8238 - val_loss: 0.4072 - val_acc: 0.8180\n",
      "Epoch 34/100\n",
      "10000/10000 [==============================] - 5s 528us/step - loss: 0.3928 - acc: 0.8271 - val_loss: 0.3955 - val_acc: 0.8180\n",
      "Epoch 35/100\n",
      "10000/10000 [==============================] - 5s 540us/step - loss: 0.3872 - acc: 0.8322 - val_loss: 0.3908 - val_acc: 0.8200\n",
      "Epoch 36/100\n",
      "10000/10000 [==============================] - 5s 530us/step - loss: 0.3830 - acc: 0.8346 - val_loss: 0.4081 - val_acc: 0.8150\n",
      "Epoch 37/100\n",
      "10000/10000 [==============================] - 6s 551us/step - loss: 0.3807 - acc: 0.8331 - val_loss: 0.3915 - val_acc: 0.8220\n",
      "Epoch 38/100\n",
      "10000/10000 [==============================] - 6s 609us/step - loss: 0.3796 - acc: 0.8342 - val_loss: 0.3851 - val_acc: 0.8180\n",
      "Epoch 39/100\n",
      "10000/10000 [==============================] - 6s 608us/step - loss: 0.3739 - acc: 0.8351 - val_loss: 0.4422 - val_acc: 0.8040\n",
      "Epoch 40/100\n",
      "10000/10000 [==============================] - 6s 612us/step - loss: 0.3722 - acc: 0.8371 - val_loss: 0.4212 - val_acc: 0.8130\n",
      "Epoch 41/100\n",
      "10000/10000 [==============================] - 6s 609us/step - loss: 0.3730 - acc: 0.8364 - val_loss: 0.3941 - val_acc: 0.8180\n",
      "Epoch 42/100\n",
      "10000/10000 [==============================] - 6s 588us/step - loss: 0.3666 - acc: 0.8385 - val_loss: 0.3761 - val_acc: 0.8210\n",
      "Epoch 43/100\n",
      "10000/10000 [==============================] - 6s 570us/step - loss: 0.3646 - acc: 0.8410 - val_loss: 0.4039 - val_acc: 0.8080\n",
      "Epoch 44/100\n",
      "10000/10000 [==============================] - 6s 573us/step - loss: 0.3605 - acc: 0.8415 - val_loss: 0.3835 - val_acc: 0.8190\n",
      "Epoch 45/100\n",
      "10000/10000 [==============================] - 6s 574us/step - loss: 0.3561 - acc: 0.8434 - val_loss: 0.3693 - val_acc: 0.8280\n",
      "Epoch 46/100\n",
      "10000/10000 [==============================] - 6s 594us/step - loss: 0.3566 - acc: 0.8420 - val_loss: 0.3909 - val_acc: 0.8310\n",
      "Epoch 47/100\n",
      "10000/10000 [==============================] - 6s 568us/step - loss: 0.3516 - acc: 0.8449 - val_loss: 0.3986 - val_acc: 0.8180\n",
      "Epoch 48/100\n",
      "10000/10000 [==============================] - 6s 569us/step - loss: 0.3481 - acc: 0.8482 - val_loss: 0.3641 - val_acc: 0.8310\n",
      "Epoch 49/100\n",
      "10000/10000 [==============================] - 6s 574us/step - loss: 0.3441 - acc: 0.8494 - val_loss: 0.3850 - val_acc: 0.8180\n",
      "Epoch 50/100\n",
      "10000/10000 [==============================] - 6s 566us/step - loss: 0.3409 - acc: 0.8509 - val_loss: 0.3730 - val_acc: 0.8340\n",
      "Epoch 51/100\n",
      "10000/10000 [==============================] - 6s 572us/step - loss: 0.3382 - acc: 0.8554 - val_loss: 0.3812 - val_acc: 0.8260\n",
      "Epoch 52/100\n",
      "10000/10000 [==============================] - 6s 571us/step - loss: 0.3388 - acc: 0.8493 - val_loss: 0.3580 - val_acc: 0.8370\n",
      "Epoch 53/100\n",
      "10000/10000 [==============================] - 6s 567us/step - loss: 0.3349 - acc: 0.8538 - val_loss: 0.3766 - val_acc: 0.8430\n",
      "Epoch 54/100\n",
      "10000/10000 [==============================] - 6s 567us/step - loss: 0.3337 - acc: 0.8565 - val_loss: 0.4061 - val_acc: 0.8320\n",
      "Epoch 55/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 5s 532us/step - loss: 0.3311 - acc: 0.8575 - val_loss: 0.3892 - val_acc: 0.8370\n",
      "Epoch 56/100\n",
      "10000/10000 [==============================] - 5s 532us/step - loss: 0.3308 - acc: 0.8585 - val_loss: 0.3636 - val_acc: 0.8290\n",
      "Epoch 57/100\n",
      "10000/10000 [==============================] - 5s 541us/step - loss: 0.3303 - acc: 0.8587 - val_loss: 0.3601 - val_acc: 0.8350\n",
      "Epoch 58/100\n",
      "10000/10000 [==============================] - 5s 530us/step - loss: 0.3237 - acc: 0.8602 - val_loss: 0.3603 - val_acc: 0.8240\n",
      "Epoch 59/100\n",
      "10000/10000 [==============================] - 5s 531us/step - loss: 0.3245 - acc: 0.8588 - val_loss: 0.3704 - val_acc: 0.8370\n",
      "Epoch 60/100\n",
      "10000/10000 [==============================] - 5s 532us/step - loss: 0.3233 - acc: 0.8625 - val_loss: 0.3662 - val_acc: 0.8290\n",
      "Epoch 61/100\n",
      "10000/10000 [==============================] - 5s 529us/step - loss: 0.3160 - acc: 0.8672 - val_loss: 0.3588 - val_acc: 0.8290\n",
      "Epoch 62/100\n",
      "10000/10000 [==============================] - 5s 535us/step - loss: 0.3245 - acc: 0.8618 - val_loss: 0.3996 - val_acc: 0.8270\n",
      "Epoch 63/100\n",
      "10000/10000 [==============================] - 5s 529us/step - loss: 0.3233 - acc: 0.8636 - val_loss: 0.3575 - val_acc: 0.8340\n",
      "Epoch 64/100\n",
      "10000/10000 [==============================] - 5s 538us/step - loss: 0.3168 - acc: 0.8637 - val_loss: 0.3970 - val_acc: 0.8350\n",
      "Epoch 65/100\n",
      "10000/10000 [==============================] - 5s 535us/step - loss: 0.3159 - acc: 0.8643 - val_loss: 0.3806 - val_acc: 0.8230\n",
      "Epoch 66/100\n",
      "10000/10000 [==============================] - 5s 528us/step - loss: 0.3198 - acc: 0.8621 - val_loss: 0.3940 - val_acc: 0.8290\n",
      "Epoch 67/100\n",
      "10000/10000 [==============================] - 5s 529us/step - loss: 0.3155 - acc: 0.8657 - val_loss: 0.3707 - val_acc: 0.8290\n",
      "Epoch 68/100\n",
      "10000/10000 [==============================] - 5s 533us/step - loss: 0.3155 - acc: 0.8604 - val_loss: 0.3823 - val_acc: 0.8280\n",
      "Epoch 69/100\n",
      "10000/10000 [==============================] - 5s 543us/step - loss: 0.3113 - acc: 0.8694 - val_loss: 0.3664 - val_acc: 0.8360\n",
      "Epoch 70/100\n",
      "10000/10000 [==============================] - 5s 529us/step - loss: 0.3108 - acc: 0.8685 - val_loss: 0.3858 - val_acc: 0.8230\n",
      "Epoch 71/100\n",
      "10000/10000 [==============================] - 5s 531us/step - loss: 0.3112 - acc: 0.8640 - val_loss: 0.3835 - val_acc: 0.8300\n",
      "Epoch 72/100\n",
      "10000/10000 [==============================] - 5s 530us/step - loss: 0.3131 - acc: 0.8688 - val_loss: 0.3898 - val_acc: 0.8270\n",
      "Epoch 73/100\n",
      "10000/10000 [==============================] - 5s 531us/step - loss: 0.3115 - acc: 0.8665 - val_loss: 0.3865 - val_acc: 0.8260\n",
      "Epoch 74/100\n",
      "10000/10000 [==============================] - 5s 530us/step - loss: 0.3035 - acc: 0.8709 - val_loss: 0.3907 - val_acc: 0.8290\n",
      "Epoch 75/100\n",
      "10000/10000 [==============================] - 5s 530us/step - loss: 0.3007 - acc: 0.8728 - val_loss: 0.4018 - val_acc: 0.8280\n",
      "Epoch 76/100\n",
      "10000/10000 [==============================] - 5s 532us/step - loss: 0.3116 - acc: 0.8693 - val_loss: 0.3782 - val_acc: 0.8250\n",
      "Epoch 77/100\n",
      "10000/10000 [==============================] - 5s 529us/step - loss: 0.3064 - acc: 0.8705 - val_loss: 0.4009 - val_acc: 0.8220\n",
      "Epoch 78/100\n",
      "10000/10000 [==============================] - 5s 534us/step - loss: 0.3047 - acc: 0.8711 - val_loss: 0.3844 - val_acc: 0.8320\n",
      "Epoch 79/100\n",
      "10000/10000 [==============================] - 5s 535us/step - loss: 0.3057 - acc: 0.8710 - val_loss: 0.3685 - val_acc: 0.8270\n",
      "Epoch 80/100\n",
      "10000/10000 [==============================] - 6s 585us/step - loss: 0.3049 - acc: 0.8744 - val_loss: 0.4201 - val_acc: 0.8240\n",
      "Epoch 81/100\n",
      "10000/10000 [==============================] - 6s 589us/step - loss: 0.2993 - acc: 0.8706 - val_loss: 0.3932 - val_acc: 0.8160\n",
      "Epoch 82/100\n",
      "10000/10000 [==============================] - 6s 608us/step - loss: 0.2942 - acc: 0.8758 - val_loss: 0.4047 - val_acc: 0.8210\n",
      "Epoch 83/100\n",
      "10000/10000 [==============================] - 6s 586us/step - loss: 0.3024 - acc: 0.8744 - val_loss: 0.3963 - val_acc: 0.8270\n",
      "Epoch 84/100\n",
      "10000/10000 [==============================] - 6s 565us/step - loss: 0.2970 - acc: 0.8743 - val_loss: 0.3903 - val_acc: 0.8290\n",
      "Epoch 85/100\n",
      "10000/10000 [==============================] - 6s 565us/step - loss: 0.3024 - acc: 0.8726 - val_loss: 0.4054 - val_acc: 0.8230\n",
      "Epoch 86/100\n",
      "10000/10000 [==============================] - 6s 560us/step - loss: 0.2951 - acc: 0.8746 - val_loss: 0.3883 - val_acc: 0.8240\n",
      "Epoch 87/100\n",
      "10000/10000 [==============================] - 6s 573us/step - loss: 0.2964 - acc: 0.8774 - val_loss: 0.4160 - val_acc: 0.8270\n",
      "Epoch 88/100\n",
      "10000/10000 [==============================] - 6s 605us/step - loss: 0.3014 - acc: 0.8731 - val_loss: 0.3775 - val_acc: 0.8320\n",
      "Epoch 89/100\n",
      "10000/10000 [==============================] - 6s 605us/step - loss: 0.2885 - acc: 0.8749 - val_loss: 0.4268 - val_acc: 0.8250\n",
      "Epoch 90/100\n",
      "10000/10000 [==============================] - 6s 585us/step - loss: 0.2898 - acc: 0.8816 - val_loss: 0.4236 - val_acc: 0.8170\n",
      "Epoch 91/100\n",
      "10000/10000 [==============================] - 6s 571us/step - loss: 0.2935 - acc: 0.8801 - val_loss: 0.4026 - val_acc: 0.8240\n",
      "Epoch 92/100\n",
      "10000/10000 [==============================] - 6s 565us/step - loss: 0.2930 - acc: 0.8795 - val_loss: 0.4125 - val_acc: 0.8260\n",
      "Epoch 93/100\n",
      "10000/10000 [==============================] - 6s 556us/step - loss: 0.2913 - acc: 0.8827 - val_loss: 0.4160 - val_acc: 0.8130\n",
      "Epoch 94/100\n",
      "10000/10000 [==============================] - 6s 559us/step - loss: 0.2922 - acc: 0.8784 - val_loss: 0.4059 - val_acc: 0.8260\n",
      "Epoch 95/100\n",
      "10000/10000 [==============================] - 6s 562us/step - loss: 0.2866 - acc: 0.8793 - val_loss: 0.4407 - val_acc: 0.8250\n",
      "Epoch 96/100\n",
      "10000/10000 [==============================] - 6s 565us/step - loss: 0.2876 - acc: 0.8796 - val_loss: 0.3955 - val_acc: 0.8240\n",
      "Epoch 97/100\n",
      "10000/10000 [==============================] - 6s 562us/step - loss: 0.2886 - acc: 0.8812 - val_loss: 0.4039 - val_acc: 0.8260\n",
      "Epoch 98/100\n",
      "10000/10000 [==============================] - 6s 568us/step - loss: 0.2836 - acc: 0.8801 - val_loss: 0.4155 - val_acc: 0.8300\n",
      "Epoch 99/100\n",
      "10000/10000 [==============================] - 6s 559us/step - loss: 0.2860 - acc: 0.8800 - val_loss: 0.4022 - val_acc: 0.8290\n",
      "Epoch 100/100\n",
      "10000/10000 [==============================] - 6s 566us/step - loss: 0.2826 - acc: 0.8819 - val_loss: 0.4456 - val_acc: 0.8090\n"
     ]
    }
   ],
   "source": [
    "history = model.fit([inputs_train,questions_train], answers_train,batch_size=32,epochs = 100,validation_data=([inputs_test,questions_test],answers_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['val_loss', 'val_acc', 'loss', 'acc'])\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "print(history.history.keys())\n",
    "plt.plot(history.history[\"acc\"])\n",
    "plt.plot(history.history[\"val_acc\"])\n",
    "plt.title(\"model accuracy\")\n",
    "plt.ylabel(\"accuracy\")\n",
    "plt.xlabel(\"epoch\")\n",
    "plt.legend([\"train\",\"test\"],loc = \"upper left\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = \"chatbot_10.h55\"\n",
    "model.save(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_results = model.predict(([inputs_test,questions_test]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 38)"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_results.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([4.5173243e-18, 4.1515012e-18, 4.8561896e-18, 5.1949672e-18,\n",
       "       4.1713130e-18, 4.7499614e-18, 5.8911617e-18, 3.9163139e-18,\n",
       "       6.2096449e-18, 9.9997151e-01, 5.7046846e-18, 4.0462148e-18,\n",
       "       5.1981390e-18, 3.4345283e-18, 5.0304501e-18, 5.4378237e-18,\n",
       "       5.2323578e-18, 3.0289727e-18, 5.6664693e-18, 6.2443256e-18,\n",
       "       4.4225555e-18, 5.1834859e-18, 3.7951849e-18, 5.8173325e-18,\n",
       "       3.8956332e-18, 4.3557846e-18, 4.3002126e-18, 2.8438311e-05,\n",
       "       5.9433949e-18, 4.8427219e-18, 6.8474367e-18, 4.0542802e-18,\n",
       "       3.7220634e-18, 5.8724939e-18, 5.3237646e-18, 5.2041307e-18,\n",
       "       4.9210484e-18, 3.9841986e-18], dtype=float32)"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_results[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gives index number of highest probaility\n",
    "val_max = np.argmax(pred_results[0]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key,val in tokenizer.word_index.items():\n",
    "    # and print the key, when val matches highest probability value\n",
    "    if val == val_max:\n",
    "        k = key      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'no'"
      ]
     },
     "execution_count": 219,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9999715"
      ]
     },
     "execution_count": 227,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_results[0][val_max]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we are going to write our own stories and questions\n",
    "# and run through actual model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we can only use the words which my model is aware of\n",
    "# the ones which are there in the vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_story = \"John left the kitchen . Sandra dropped the football in the garden .\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['John',\n",
       " 'left',\n",
       " 'the',\n",
       " 'kitchen',\n",
       " '.',\n",
       " 'Sandra',\n",
       " 'dropped',\n",
       " 'the',\n",
       " 'football',\n",
       " 'in',\n",
       " 'the',\n",
       " 'garden',\n",
       " '.']"
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_story.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_question = \"Is the football in the garden ?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "mydata = [(my_story.split() , my_question.split(),\"yes\")] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(['John',\n",
       "   'left',\n",
       "   'the',\n",
       "   'kitchen',\n",
       "   '.',\n",
       "   'Sandra',\n",
       "   'dropped',\n",
       "   'the',\n",
       "   'football',\n",
       "   'in',\n",
       "   'the',\n",
       "   'garden',\n",
       "   '.'],\n",
       "  ['Is', 'the', 'football', 'in', 'the', 'garden', '?'],\n",
       "  'yes')]"
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mydata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_story, my_ques, my_ans = vectorize_stories(mydata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_res = model.predict(([my_story,my_ques]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_max1 = np.argmax(pred_res[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key,val in tokenizer.word_index.items():\n",
    "    if val == val_max1:\n",
    "        k = key\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'yes'"
      ]
     },
     "execution_count": 224,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9793636"
      ]
     },
     "execution_count": 226,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_res[0][val_max1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
